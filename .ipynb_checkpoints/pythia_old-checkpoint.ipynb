{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed4ff3b-ef77-4693-9747-9e3a6cc9c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(levelname)s [%(name)s] %(message)s\", level=logging.INFO, datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "logging.getLogger(\"py4j\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"sh.command\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2ccc2-5e72-4fa2-9abe-a13571f5132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from training.consts import DEFAULT_INPUT_MODEL, SUGGESTED_INPUT_MODELS\n",
    "from training.trainer import load_training_dataset, load_tokenizer\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "model_name = \"dolly\"\n",
    "\n",
    "experiment_id = \"1\"\n",
    "input_model = \"pythia_models/pythia-2.8b\"\n",
    "\n",
    "if experiment_id:\n",
    "    experiment_id = re.sub(r\"\\s+\", \"_\", experiment_id.strip())\n",
    "    model_name = f\"{model_name}__{experiment_id}\"\n",
    "\n",
    "checkpoint_dir_name = f\"{model_name}__{timestamp}\"\n",
    "\n",
    "dolly_training_dir_name = \"dolly_training\"\n",
    "\n",
    "# Use the local training root path if it was provided.  Otherwise try to find a sensible default.\n",
    "local_training_root = dbutils.widgets.get(\"local_training_root\")\n",
    "if not local_training_root:\n",
    "    # Use preferred path when working in a Databricks cluster if it exists.\n",
    "    if os.path.exists(\"/local_disk0\"):\n",
    "        local_training_root = os.path.join(\"/local_disk0\", dolly_training_dir_name)\n",
    "    # Otherwise use the home directory.\n",
    "    else:\n",
    "        local_training_root = os.path.join(os.path.expanduser('~'), dolly_training_dir_name)\n",
    "\n",
    "dbfs_output_root = dbutils.widgets.get(\"dbfs_output_root\")\n",
    "if not dbfs_output_root:\n",
    "    dbfs_output_root = f\"/dbfs/{dolly_training_dir_name}\"\n",
    "\n",
    "os.makedirs(local_training_root, exist_ok=True)\n",
    "os.makedirs(dbfs_output_root, exist_ok=True)\n",
    "\n",
    "local_output_dir = os.path.join(local_training_root, checkpoint_dir_name)\n",
    "dbfs_output_dir = os.path.join(dbfs_output_root, checkpoint_dir_name)\n",
    "tensorboard_display_dir = f\"{local_output_dir}/runs\"\n",
    "\n",
    "print(f\"Local Output Dir: {local_output_dir}\")\n",
    "print(f\"DBFS Output Dir: {dbfs_output_dir}\")\n",
    "print(f\"Tensorboard Display Dir: {tensorboard_display_dir}\")\n",
    "\n",
    "# pick an appropriate config file\n",
    "gpu_family = dbutils.widgets.get(\"gpu_family\")\n",
    "config_file_name = f\"{gpu_family}_config.json\"\n",
    "deepspeed_config = os.path.join(os.getcwd(), \"config\", config_file_name)\n",
    "print(f\"Deepspeed config file: {deepspeed_config}\")\n",
    "\n",
    "# configure the batch_size\n",
    "batch_size = 3\n",
    "if gpu_family == \"a10\":\n",
    "    batch_size = 4\n",
    "elif gpu_family == \"a100\":\n",
    "    batch_size = 6\n",
    "\n",
    "# configure num_gpus, if specified\n",
    "num_gpus_flag = \"\"\n",
    "num_gpus = dbutils.widgets.get(\"num_gpus\")\n",
    "if num_gpus:\n",
    "    num_gpus = int(num_gpus)\n",
    "    num_gpus_flag = f\"--num_gpus={num_gpus}\"\n",
    "\n",
    "if gpu_family == \"v100\":\n",
    "    bf16_flag = \"--bf16 false\"\n",
    "else:\n",
    "    bf16_flag = \"--bf16 true\"\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %load_ext tensorboard\n",
    "# MAGIC %tensorboard --logdir '{tensorboard_display_dir}'\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "!deepspeed {num_gpus_flag} \\\n",
    "    --module training.trainer \\\n",
    "    --input-model {input_model} \\\n",
    "    --deepspeed {deepspeed_config} \\\n",
    "    --epochs 2 \\\n",
    "    --local-output-dir {local_output_dir} \\\n",
    "    --dbfs-output-dir {dbfs_output_dir} \\\n",
    "    --per-device-train-batch-size {batch_size} \\\n",
    "    --per-device-eval-batch-size {batch_size} \\\n",
    "    --logging-steps 10 \\\n",
    "    --save-steps 200 \\\n",
    "    --save-total-limit 20 \\\n",
    "    --eval-steps 50 \\\n",
    "    --warmup-steps 50 \\\n",
    "    --test-size 200 \\\n",
    "    --lr 5e-6 \\\n",
    "    {bf16_flag}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834794bc-62b7-4edd-8903-2c3ede18b202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch113]",
   "language": "python",
   "name": "conda-env-torch113-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
