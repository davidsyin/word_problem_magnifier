{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcusparse-dev-11-3_11.5.0.58-1_amd64.deb -O /tmp/libcusparse-dev-11-3_11.5.0.58-1_amd64.deb && \\\n",
    "sudo wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcublas-dev-11-3_11.5.1.109-1_amd64.deb -O /tmp/libcublas-dev-11-3_11.5.1.109-1_amd64.deb && \\\n",
    "sudo wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcusolver-dev-11-3_11.1.2.109-1_amd64.deb -O /tmp/libcusolver-dev-11-3_11.1.2.109-1_amd64.deb && \\\n",
    "sudo wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcurand-dev-11-3_10.2.4.109-1_amd64.deb -O /tmp/libcurand-dev-11-3_10.2.4.109-1_amd64.deb && \\\n",
    "sudo dpkg -i /tmp/libcusparse-dev-11-3_11.5.0.58-1_amd64.deb && \\\n",
    "sudo dpkg -i /tmp/libcublas-dev-11-3_11.5.1.109-1_amd64.deb && \\\n",
    "sudo dpkg -i /tmp/libcusolver-dev-11-3_11.1.2.109-1_amd64.deb && \\\n",
    "sudo dpkg -i /tmp/libcurand-dev-11-3_10.2.4.109-1_amd64.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'27 * 7367 = 2 7 * 7 3 6 7 = < [ { ( 2 * 7 = 1 4 ) shifted 1 = 1 4 0 } + ( 7 * 7 = 4 9 ) = 1 8 9 ] shifted 3 = 1 8 9 0 0 0 > + < [ { ( 2 * 3 = 6 ) shifted 1 = 6 0 } + ( 7 * 3 = 2 1 ) = 8 1 ] shifted 2 = 8 1 0 0 > + < [ { ( 2 * 6 = 1 2 ) shifted 1 = 1 2 0 } + ( 7 * 6 = 4 2 ) = 1 6 2 ] shifted 1 = 1 6 2 0 > + [ { ( 2 * 7 = 1 4 ) shifted 1 = 1 4 0 } + ( 7 * 7 = 4 9 ) = 1 8 9 ] = 1 8 9 0 0 0 + 8 1 0 0 + 1 6 2 0 + 1 8 9 = 1 9 7 1 0 0 + 1 6 2 0 + 1 8 9 = 1 9 8 7 2 0 + 1 8 9 = 1 9 8 9 0 9 '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def space(a):\n",
    "    res=\"\"\n",
    "    for i in range(len(a)):\n",
    "        res+=a[i]\n",
    "        if i!=len(a)-1:\n",
    "            res+=\" \"\n",
    "    return res\n",
    "def to_words_mult(a,b):\n",
    "    res=a+\" * \"+b+\" = \"+space(a)+\" * \"+space(b)+\" = \"\n",
    "    for i in range(len(b)):\n",
    "        if i!=len(b)-1:\n",
    "            res+=\"< \"\n",
    "        res+=\"[ \"\n",
    "        for j in range(len(a)):\n",
    "            if j!=len(a)-1:\n",
    "                res+=\"{ \"\n",
    "            if len(a)-j>1:\n",
    "                res+=\"( \"+a[j]+\" * \"+b[i]+\" = \"+space(str(int(a[j])*int(b[i])))+\" ) \"\n",
    "                res+=\"shifted \"+str(len(a)-j-1)\n",
    "                res+=\" = \"+space(str(int(a[j])*int(b[i])*10**(len(a)-j-1)))\n",
    "            else:\n",
    "                res+=\"( \"+a[j]+\" * \"+b[i]+\" = \"+space(str(int(a[j])*int(b[i])))+\" )\"\n",
    "            if j!=len(a)-1:\n",
    "                res+=\" }\"\n",
    "            if j!=len(a)-1:\n",
    "                res+=\" + \"\n",
    "        res+=\" = \"+space(str(int(a)*int(b[i])))\n",
    "        res+=\" ] \"\n",
    "        if len(b)-i>1:\n",
    "            res+=\"shifted \"+str(len(b)-i-1) \n",
    "            res+=\" = \"+space(str(int(a)*int(b[i])*10**(len(b)-i-1)))\n",
    "            res+=\" \"\n",
    "        if i!=len(b)-1:\n",
    "            res+=\">\"\n",
    "        if i!=len(b)-1:\n",
    "            res+=\" + \"\n",
    "    res+=\"= \"\n",
    "    nums=[]\n",
    "    for i in range(len(b)):\n",
    "        num=str(int(a)*int(b[i])*10**(len(b)-i-1))\n",
    "        for j in str(int(a)*int(b[i])*10**(len(b)-i-1)):\n",
    "            res+=j+\" \"\n",
    "        nums.append(num)\n",
    "        if i!=len(b)-1:\n",
    "            res+=\"+ \"\n",
    "    sum=int(nums[0])\n",
    "    for i in range(1,len(nums)):\n",
    "        sum+=int(nums[i])\n",
    "        if i==len(nums)-1:\n",
    "            res+=\"= \"\n",
    "            for j in str(int(a)*int(b)):\n",
    "                res+=j+\" \"\n",
    "            break\n",
    "        res+=\"= \"\n",
    "        for j in str(sum):\n",
    "            res+=j+\" \"\n",
    "        if i<len(nums)-1:\n",
    "            res+=\"+ \"\n",
    "            for j in range(i+1,len(nums)):\n",
    "                for k in nums[j]:\n",
    "                    res+=k+\" \"\n",
    "                if j!=len(nums)-1:\n",
    "                    res+=\"+ \"\n",
    "    return res\n",
    "def to_words_div(a,b):\n",
    "    res=\"\"\n",
    "    res+=a+\" / \"+b+\" = \"+space(a)+\" / \"+space(b)\n",
    "    res+=\" =\"\n",
    "    rem=int(a)\n",
    "    res+=\" < \"\n",
    "    res+=\"[\"\n",
    "    mid_reses=[]\n",
    "    first=True\n",
    "    prev_remainder=-1\n",
    "    while rem>=int(b):\n",
    "        digits=1\n",
    "        while(int(str(rem)[:digits])<int(b)):\n",
    "            digits+=1\n",
    "        mid_res=math.floor(int(str(rem)[:digits])/int(b))\n",
    "        res+=\" { \"\n",
    "        res+=\"( \"\n",
    "        tmp=prev_remainder\n",
    "        prev_remainder=int(str(rem)[:digits])-mid_res*int(b)\n",
    "        if not first:\n",
    "            res+=space(str(tmp))+\" shifted 1\"+\" + \"+str(rem)[digits-1]+\" = \"\n",
    "        res+=space(str(rem)[:digits])+\" / \"+space(b)+\" #\"\n",
    "        res+=\" because \"+str(mid_res)+\" * \"+space(b)+\" $ \"+space(str(rem)[:digits])\n",
    "        res+=\" |\"\n",
    "        res+=\" \"+str(mid_res)+\",\"\n",
    "        res+=\" remainder \"+\"= \"+space(str(rem)[:digits])+\" - \"+str(mid_res)+\" * \"+space(b)+\" = \"+space(str(rem)[:digits])+\" - \"+space(str(mid_res*int(b)))+\" = \"+space(str(prev_remainder))+\" )\"\n",
    "        if len(str(rem))-digits>0:\n",
    "            res+=\" shifted \"+str(len(str(rem))-digits)\n",
    "        res+=\" = \"+space(str(mid_res*10**(len(str(rem))-digits)))\n",
    "        mid_reses.append(mid_res*(10**(len(str(rem))-digits)))\n",
    "        rem-=int(b)*mid_res*(10**(len(str(rem))-digits))\n",
    "        res+=\" }\"\n",
    "        if rem>=int(b):\n",
    "            res+=\" +\"  \n",
    "        first=False\n",
    "    res+=\" ]\"\n",
    "    sum=0\n",
    "    for i in range(len(mid_reses)):\n",
    "        sum+=int(mid_reses[i])\n",
    "        res+=\" = \"\n",
    "        res+=space(str(sum))\n",
    "        if i!=len(mid_reses)-1:\n",
    "            res+=\" + \"\n",
    "        for j in range(i+1,len(mid_reses)):\n",
    "            res+=space(str(mid_reses[j]))\n",
    "            if j!=len(mid_reses)-1:\n",
    "                res+=\" + \"\n",
    "    res+=\" >\"\n",
    "    res+=\" = \"+space(str(int(int(a)/int(b))))+\" remainder \"+space(str(rem))\n",
    "    return res\n",
    "def to_words_add(a,b):\n",
    "    res=\"\"\n",
    "    res+=a+\" + \"+b+\" = \"\n",
    "    a_spaced=space(a)\n",
    "    b_spaced=space(b)\n",
    "    res+=a_spaced+\" + \"+b_spaced+\" = \"\n",
    "    res+=space(str(int(a)+int(b)))\n",
    "    return res\n",
    "def to_words_sub(a,b):\n",
    "    res=\"\"\n",
    "    res+=a+\" - \"+b+\" = \"\n",
    "    a_spaced=space(a)    \n",
    "    b_spaced=space(b)\n",
    "    res+=a_spaced+\" - \"+b_spaced+\" = \"\n",
    "    res+=space(str(int(a)-int(b)))\n",
    "    return res\n",
    "to_words_mult(\"27\",\"7367\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "def make_data(path,n):\n",
    "    for i in range(n):\n",
    "        operation=random.randint(1,4)\n",
    "        if str(operation) in \"1\":\n",
    "            digits_1=random.randint(3,4)\n",
    "            digits_2=random.randint(3,4)\n",
    "            a=random.randint(10**(digits_1-1),(10**digits_1)-1)\n",
    "            b=random.randint(10**(digits_2-1),(10**digits_2)-1)\n",
    "            instructions=str(a)+\" * \"+str(b)\n",
    "            response=to_words_mult(str(a),str(b))\n",
    "            question={\"instruction\":instructions, \"context\": \"\", \"category\": \"open_qa\", \"response\": response}\n",
    "            with open(path, \"a\") as outfile:\n",
    "                json.dump(question, outfile)\n",
    "                outfile.write(\"\\n\")\n",
    "        if str(operation) in \"2\":\n",
    "            digits_1=random.randint(3,4)\n",
    "            digits_2=random.randint(2,digits_1)\n",
    "            a=random.randint(10**(digits_1-1),(10**digits_1)-1)\n",
    "            b=random.randint(max(10**(digits_2-1),1),min((10**digits_2)-1,a))\n",
    "            instructions=str(a)+\" / \"+str(b)\n",
    "            response=to_words_div(str(a),str(b))\n",
    "            question={\"instruction\":instructions, \"context\": \"\", \"category\": \"open_qa\", \"response\": response}\n",
    "            with open(path, \"a\") as outfile:\n",
    "                json.dump(question, outfile)\n",
    "                outfile.write(\"\\n\")\n",
    "        if operation==3:\n",
    "            digits_1=random.randint(3,7)\n",
    "            digits_2=random.randint(3,7)\n",
    "            a=random.randint(10**(digits_1-1),(10**digits_1)-1)\n",
    "            b=random.randint(10**(digits_1-1),(10**digits_1)-1)\n",
    "            instructions=str(a)+\" + \"+str(b)\n",
    "            response=to_words_add(str(a),str(b))\n",
    "            question={\"instruction\":instructions, \"context\": \"\", \"category\": \"open_qa\", \"response\": response}\n",
    "            with open(path, \"a\") as outfile:\n",
    "                json.dump(question, outfile)\n",
    "                outfile.write(\"\\n\")\n",
    "        if operation==4:\n",
    "            digits_1=random.randint(3,7)\n",
    "            digits_2=random.randint(2,digits_1)\n",
    "            a=random.randint(10**(digits_1-1),(10**digits_1)-1)\n",
    "            b=random.randint(max(10**(digits_2-1),1),min((10**digits_2)-1,a))\n",
    "            instructions=str(a)+\" - \"+str(b)\n",
    "            response=to_words_sub(str(a),str(b))\n",
    "            question={\"instruction\":instructions, \"context\": \"\", \"category\": \"open_qa\", \"response\": response}\n",
    "            with open(path, \"a\") as outfile:\n",
    "                json.dump(question, outfile)\n",
    "                outfile.write(\"\\n\")\n",
    "        \n",
    "make_data(\"/home/mcwave/data/multiplication_data/400k/400k.jsonl\",400000)\n",
    "# make_data(\"/home/mcwave/data/multiplication_data/240k.jsonl\",240000)\n",
    "# make_data(\"/home/mcwave/data/multiplication_data/360k.jsonl\",360000)\n",
    "# make_data(\"/home/mcwave/data/multiplication_data/480k.jsonl\",480000)\n",
    "# make_data(\"/home/mcwave/data/multiplication_data/600k.jsonl\",600000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0024337768554688"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "time_1=time.time()\n",
    "time.sleep(2)\n",
    "time_2=time.time()\n",
    "time_2-time_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f=open(\"/home/mcwave/code/ChatGLM-6B/ptuning/word_problems/word_problems_train_data_2/word_problems_train_data_2_eqs.json\")\n",
    "data=json.load(f)\n",
    "def split(data,n,folder):\n",
    "    seen={\"temp\"}\n",
    "    i=0\n",
    "    while i<n:\n",
    "        problem=random.choice(data)\n",
    "        if problem[\"instruction\"] in seen:\n",
    "            continue\n",
    "        else:\n",
    "            seen.add(problem[\"instruction\"])\n",
    "            with open(\"/home/mcwave/data/word_problems/\"+folder+\"word_problems.json\",\"a\") as outfile:\n",
    "                json.dump(problem,outfile)\n",
    "                outfile.write(\"\\n\")\n",
    "            i+=1\n",
    "split(data,1000,\"1k\")\n",
    "split(data,2000,\"2k\")\n",
    "split(data,4000,\"4k\")\n",
    "split(data,5657,\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "import os\n",
    "from transformers import LlamaTokenizer\n",
    "\n",
    "timestamp = \"\"\n",
    "\n",
    "model_path = \"/home/mcwave/models/pythia_models/pythia-6.9b-output_pred\"#put model path here\n",
    "\n",
    "experiment_id = \"\"\n",
    "input_model = model_path\n",
    "\n",
    "if experiment_id:\n",
    "    experiment_id = re.sub(r\"\\s+\", \"_\", experiment_id.strip())\n",
    "    model_name = f\"{model_name}__{experiment_id}\"\n",
    "\n",
    "checkpoint_dir_name = \"model\"\n",
    "\n",
    "root_path = os.getcwd()\n",
    "deepspeed_config = os.path.join(root_path, \"config/dolly_config.json\")\n",
    "\n",
    "dolly_training_dir_name = \"dolly_training\"\n",
    "\n",
    "local_training_root = model_path\n",
    "\n",
    "dbfs_output_root = \"/home/mcwave/code/results\"#model will save both here and in the model folder\n",
    "if not dbfs_output_root:\n",
    "    dbfs_output_root = f\"/dbfs/{dolly_training_dir_name}\"\n",
    "\n",
    "os.makedirs(local_training_root, exist_ok=True)\n",
    "os.makedirs(dbfs_output_root, exist_ok=True)\n",
    "\n",
    "local_output_dir = os.path.join(local_training_root, \"\")\n",
    "dbfs_output_dir = os.path.join(dbfs_output_root, checkpoint_dir_name)\n",
    "\n",
    "num_gpus_flag = \"\"\n",
    "num_gpus = \"2\"\n",
    "if num_gpus:\n",
    "    num_gpus = int(num_gpus)\n",
    "    num_gpus_flag = f\"--num_gpus={num_gpus}\"\n",
    "model_flag=f\"{model_path}\"\n",
    "\n",
    "tensorboard_display_dir = f\"{local_output_dir}/runs\"\n",
    "\n",
    "print(f\"Local Output Dir: {local_output_dir}\")\n",
    "print(f\"DBFS Output Dir: {dbfs_output_dir}\")\n",
    "print(f\"Tensorboard Display Dir: {tensorboard_display_dir}\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %load_ext tensorboard\n",
    "# MAGIC %tensorboard --logdir '{tensorboard_display_dir}'\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "!deepspeed {num_gpus_flag}\\\n",
    "     --module training.trainer \\\n",
    "     --input-model {input_model} \\\n",
    "     --deepspeed {deepspeed_config} \\\n",
    "     --epochs 50 \\\n",
    "     --local-output-dir {local_output_dir} \\\n",
    "     --dbfs-output-dir {dbfs_output_dir} \\\n",
    "     --per-device-train-batch-size 5 \\\n",
    "     --per-device-eval-batch-size 5 \\\n",
    "     --logging-steps 10 \\\n",
    "     --save-steps 300 \\\n",
    "     --save-total-limit 9999 \\\n",
    "     --eval-steps 50 \\\n",
    "     --warmup-steps 0 \\\n",
    "     --test-size 200 \\\n",
    "     --lr 5e-6 \\\n",
    "\n",
    "# # COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-10 20:21:47,297] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Model path:/home/mcwave/code/llama2/databricks-ml-examples/llm-models/llamav2/llamav2-7b/output/checkpoint-800\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for '/home/mcwave/code/llama2/databricks-ml-examples/llm-models/llamav2/llamav2-7b/output/checkpoint-800'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mcwave/code/llama2/databricks-ml-examples/llm-models/llamav2/llamav2-7b/output/checkpoint-800' is the correct path to a directory containing all relevant files for a LlamaTokenizerFast tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_response, load_model_tokenizer_for_generate\n\u001b[0;32m----> 2\u001b[0m model,tokenizer\u001b[38;5;241m=\u001b[39m\u001b[43mload_model_tokenizer_for_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/mcwave/code/llama2/databricks-ml-examples/llm-models/llamav2/llamav2-7b/output/checkpoint-800\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#pythia_model,pythia_tokenizer=load_model_tokenizer_for_generate(\"/home/mcwave/models/pythia_models/pythia-6.9b\")\u001b[39;00m\n",
      "File \u001b[0;32m~/code/word_problem_magnifier/training/generate.py:37\u001b[0m, in \u001b[0;36mload_model_tokenizer_for_generate\u001b[0;34m(pretrained_model_name_or_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads the model and tokenizer so that it can be used for generating responses.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    Tuple[PreTrainedModel, PreTrainedTokenizer]: model and tokenizer\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel path:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mpretrained_model_name_or_path)\n\u001b[0;32m---> 37\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     39\u001b[0m     pretrained_model_name_or_path, device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, tokenizer\n",
      "File \u001b[0;32m~/anaconda3/envs/llama2/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:745\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[38;5;241m=\u001b[39m TOKENIZER_MAPPING[\u001b[38;5;28mtype\u001b[39m(config)]\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_fast \u001b[38;5;129;01mand\u001b[39;00m (use_fast \u001b[38;5;129;01mor\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/llama2/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1838\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1832\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   1833\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load following files from cache: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munresolved_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and cannot check if these \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1834\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles are necessary for the tokenizer to operate.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1835\u001b[0m     )\n\u001b[1;32m   1837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m-> 1838\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   1839\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1841\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1842\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1843\u001b[0m     )\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for '/home/mcwave/code/llama2/databricks-ml-examples/llm-models/llamav2/llamav2-7b/output/checkpoint-800'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mcwave/code/llama2/databricks-ml-examples/llm-models/llamav2/llamav2-7b/output/checkpoint-800' is the correct path to a directory containing all relevant files for a LlamaTokenizerFast tokenizer."
     ]
    }
   ],
   "source": [
    "from training.generate import generate_response, load_model_tokenizer_for_generate\n",
    "model,tokenizer=load_model_tokenizer_for_generate(\"/home/mcwave/code/llama2/databricks-ml-examples/llm-models/llamav2/llamav2-7b/output/checkpoint-800\")\n",
    "#pythia_model,pythia_tokenizer=load_model_tokenizer_for_generate(\"/home/mcwave/models/pythia_models/pythia-6.9b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: spoon_type = \"teaspoon\"\n",
      "spoon_material = \"stainless steel\"\n",
      "spoon_color = \"silver\"\n",
      "print(\"Spoon Type: \" + spoon_type)\n",
      "print(\"Spoon Material: \" + spoon_material)\n",
      "print(\"Spoon Color: \" + spoon_color)\n",
      "spoon_type += \"s\"  # Make it plural\n",
      "spoon_color = \"gold\"  # Change the color\n",
      "print(\"Updated Spoon Type: \" + spoon_type)\n",
      "print(\"Updated Spoon Material: \" + spoon_material)\n",
      "print(\"Updated Spoon Color: \" + spoon_color)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "variables:  [ spoon_type : teaspoon\n",
      " ],  [ spoon_material : stainless steel\n",
      " ],  [ spoon_color : silver\n",
      " ], None, None, None,  [  ( spoon_type : spoon\n",
      " spoon_material : \n",
      "stainless steel\n",
      " spoon_color : \n",
      "silver\n",
      " )  ],  [ spoon_type : spoons\n",
      " ],  [ spoon_color : gold\n",
      " ], None, None, None,  [  ( Updated spoon_type : spoon\n",
      " Updated spoon_material : \n",
      "stainless steel\n",
      " Updated spoon_color : \n",
      "gold\n",
      " )  ],  [ spoon_type : spoons\n",
      " ],  [ spoon_color : None\n",
      " ], None, None, None, None, stdout:  ( Spoon Type: teaspoon\n",
      "Spoon Material: stainless steel\n",
      "Spoon Color: silver\n",
      "None\n",
      "Updated Spoon Type: spoons\n",
      "Updated Spoon Material: \n",
      "stainless steel\n",
      "Updated Spoon Color: \n",
      "gold\n",
      "None\n",
      " )\n",
      "\n",
      "-----------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions_2 = [ \n",
    "    \"487 / 81\", \n",
    "    \"342 / 81\", \n",
    "    \"499 / 81\", \n",
    "    \"4295 / 81\", \n",
    "    \"9635 / 3711\"]\n",
    "\n",
    "instructions_3=[\n",
    "    \"a factory produces 22 shirts a minute . how many shirts does the factory make in 156 minutes ?\",\n",
    "    \"betty is buying a wallet for 42 dollars . her parents gave her 17 dollars . how much more money does she need to buy the wallet ?\",\n",
    "    \"there are 37 bananas growing on a tree. 26 new bananas grew . how many bananas are there on the tree ?\",\n",
    "    \"a machine sharpens 10 pencils every 2 minutes . how many pencils can it sharpen in one minute ?\",\n",
    "    \"joe is selling lemonade for 4 dollars a cup . he made 52 dollars . how many cups of lemonade did he sell ?\",\n",
    "    \"a train travels 12 miles per second . how many miles can it travel in 5 seconds ?\",\n",
    "    \"a factory produces 2 toys per second. how long will it take to produce 164 toys ?\",\n",
    "    \"a factory produces 12 keyboards a minute . how many keyboards does the factory make in 15 minutes ?\",\n",
    "    \"the base for a cup of lemonade costs 23 cents . the cup costs 19 cents . how much does the lemonade cost in total ?\",\n",
    "    \"bobby is playing golf for 60 minutes . he can play one hole every 10 minutes . how many holes can he play ?\",\n",
    "    \"a factory produces 23 boxes a hour . how many hours would it take to produce 493 boxes ?\",\n",
    "    \"kevin is buying a console for 400 dollars . he sold lemonade for 264 dollars . how much more money does he need to buy the console ?\",\n",
    "    \"there are 37 boxes of apples . each box sells for 19 dollars . how much do the boxes sell for altogether ?\",\n",
    "    \"a machine serves 12 customers every 2 minutes . how many customers can it serve in 1 minute ?\",\n",
    "    \"joe is mowing lawns for 4 dollars a lawn . he made 52 dollars . how many lawns did he mow ?\",\n",
    "    \"a ship travels 123 miles per hour . how many miles can it travel in 5 hours ?\",\n",
    "    \"a factory produces 3 toys per second. how long will it take to produce 165 toys ?\",\n",
    "    \"a factory produces 12 sodas a second . how many sodas can be produced in 11 seconds ?\",\n",
    "    \"the base for a can of soda costs 153 cents . the can costs 24 cents . how much does the soda cost in total ?\",\n",
    "    \"bobby can score one point every 4 minutes . how many points can he score in 60 minutes ?\"\n",
    "]\n",
    "instructions_4=[\"spoon_type = \\\"teaspoon\\\"\\nspoon_material = \\\"stainless steel\\\"\\nspoon_color = \\\"silver\\\"\\nprint(\\\"Spoon Type: \\\" + spoon_type)\\nprint(\\\"Spoon Material: \\\" + spoon_material)\\nprint(\\\"Spoon Color: \\\" + spoon_color)\\nspoon_type += \\\"s\\\"  # Make it plural\\nspoon_color = \\\"gold\\\"  # Change the color\\nprint(\\\"Updated Spoon Type: \\\" + spoon_type)\\nprint(\\\"Updated Spoon Material: \\\" + spoon_material)\\nprint(\\\"Updated Spoon Color: \\\" + spoon_color)\\n\\n\\n\"]\n",
    "answers_3=[\" 3 4 3 2\",\" 2 5\",\" 6 3\",\" 5 remainder 0\",\" 1 3 remainder 0\",\" 6 0\",\" 8 2\",\" 1 8 0\",\" 4 2\",\" 6 remainder 0\",\" 2 1\",\" 1 3 6\",\" 7 0 3\",\" 6 remainder 0\",\" 1 3 remainder 0\",\" 6 1 5\",\" 5 5 remainder 0\",\" 1 3 2\",\" 1 7 7\",\" 1 5 remainder 0\"]\n",
    "it=0\n",
    "correct=0\n",
    "for instruction in instructions_4:\n",
    "    response = generate_response(instruction, model=model, tokenizer=tokenizer) \n",
    "    if response: \n",
    "        print(f\"Instruction: {instruction}\\n\\n{response}\\n\\n-----------\\n\")\n",
    "        i=len(response)-1\n",
    "    it+=1\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "f=open(\"/home/mcwave/data/python/code-test.json\")\n",
    "data=json.load(f)\n",
    "for i in data:\n",
    "    q=i[\"instruction\"]\n",
    "    with open(\"/home/mcwave/data/python/resilts-0901.json\",\"a\") as outfile:\n",
    "        json.dump({\"instruction\":q,\"response\":generate_response(q, model=model, tokenizer=tokenizer)},outfile)\n",
    "        outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f=open(\"/home/mcwave/data/word_problems/SVAMP/dev_svamp_big.json\")\n",
    "data=json.load(f)\n",
    "incorrect=0\n",
    "for i in range(len(data)):\n",
    "    instruction=data[i][\"question\"]\n",
    "    response_1=generate_response(instruction,model=model,tokenizer=tokenizer)\n",
    "    response_2=generate_response(instruction,model=pythia_model,tokenizer=pythia_tokenizer)\n",
    "    ans_2=\"\"\n",
    "    correct_1=False\n",
    "    correct_2=False\n",
    "    correct_ans=\"\"\n",
    "    j=len(data[i][\"answer\"])-1\n",
    "    while data[i][\"answer\"][j]!=\"=\":\n",
    "        if data[i][\"answer\"][j]!=\" \":\n",
    "            correct_ans=data[i][\"answer\"][j]+correct_ans\n",
    "        j-=1\n",
    "    if response_1:\n",
    "        model_ans=\"\"\n",
    "        j=len(response_1)-1\n",
    "        while response_1[j]!=\"=\":\n",
    "            if response_1[j]!=\" \":\n",
    "                model_ans=response_1[j]+model_ans\n",
    "            j-=1\n",
    "        if model_ans==correct_ans:\n",
    "            correct_1=True\n",
    "    if response_2:\n",
    "        model_ans_2=\"\"\n",
    "        j=len(response_2)-1\n",
    "        while response_2[j] in \"0123456789.\":\n",
    "            if response_2[j]!=\" \":\n",
    "                model_ans_2=response_2[j]+model_ans_2\n",
    "            j-=1\n",
    "        ans_2=model_ans_2\n",
    "        if model_ans_2==correct_ans:\n",
    "            correct_2=True\n",
    "    print(\"Correct answer\",correct_ans)\n",
    "    print(\"Trained answer\",model_ans)\n",
    "    print(\"Untrained answer\",model_ans_2)\n",
    "    res_dict={\"question\":instruction,\"answer\":response_1,\"correct\":correct_ans}\n",
    "    with open(\"/home/mcwave/data/word_problems/SVAMP/results/untrained.json\",\"a\") as outfile:\n",
    "        json.dump(res_dict,outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "    res_dict_2={\"question\":instruction,\"answer\":response_2,\"correct\":correct_ans}\n",
    "    with open(\"/home/mcwave/data/word_problems/SVAMP/results/trained.json\",\"a\") as outfile:\n",
    "        json.dump(res_dict_2,outfile)\n",
    "        outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f=open(\"/home/mcwave/data/word_problems/SVAMP/dev_big_3.json\")#DEV_BIG_3 for word problems\n",
    "data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "paths=os.listdir(\"/home/mcwave/models/pythia_models/pythia-6.9b-wordproblems-orig2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tokenizer_config.json',\n",
       " 'checkpoint-300',\n",
       " 'checkpoint-900',\n",
       " '.gitattributes',\n",
       " 'pytorch_model-00002-of-00002.bin',\n",
       " 'README.md',\n",
       " 'checkpoint-400',\n",
       " 'checkpoint-200',\n",
       " 'checkpoint-100',\n",
       " 'checkpoint-700',\n",
       " 'config.json',\n",
       " 'pytorch_model-00001-of-00002.bin',\n",
       " 'checkpoint-500',\n",
       " 'checkpoint-800',\n",
       " 'tokenizer.json',\n",
       " 'runs',\n",
       " '.git',\n",
       " 'checkpoint-600',\n",
       " 'pytorch_model.bin.index.json',\n",
       " '.ipynb_checkpoints',\n",
       " 'special_tokens_map.json']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    if \"checkpoint-\" not in path:\n",
    "        continue\n",
    "    model,tokenizer=load_model_tokenizer_for_generate(os.path.join(\"/home/mcwave/models/pythia_models/pythia-6.9b-wordproblems-orig2\",path))\n",
    "    i=0\n",
    "    it=0\n",
    "    correct=0\n",
    "    incorrect=0\n",
    "    while it<325:\n",
    "        try:\n",
    "            q=data[i][\"instruction\"]\n",
    "            a=data[i][\"response\"]\n",
    "            #print(\"Correct answer: \"+a)\n",
    "            response=generate_response(q,model=model,tokenizer=tokenizer)\n",
    "            #print(\"Model answer: \"+response)\n",
    "            if a==response:\n",
    "                correct+=1\n",
    "            else:\n",
    "                incorrect+=1\n",
    "                #print(data[i])\n",
    "            #print(\"Correct\",correct)\n",
    "            #print(\"Incorrect\",incorrect)\n",
    "            i+=1\n",
    "            it+=1\n",
    "            if i%10==0:\n",
    "                print(i)\n",
    "                print(\"Correct\",correct)\n",
    "                print(\"Incorrect\",incorrect)\n",
    "        except:\n",
    "            #print(\"Error\")\n",
    "            it+=1\n",
    "    print(\"Model\",path)\n",
    "    print(\"Correct\",correct)\n",
    "    print(\"Incorrect\",incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "def get_eval_set(x):\n",
    "    res=[]\n",
    "    for i in range(x):\n",
    "        operation=random.randint(1,4)\n",
    "        if str(operation) in \"1\":\n",
    "            digits_1=random.randint(2,4)\n",
    "            digits_2=random.randint(2,4)\n",
    "            a=random.randint(10**(digits_1-1),(10**digits_1)-1)\n",
    "            b=random.randint(10**(digits_2-1),(10**digits_2)-1)\n",
    "            instructions=str(a)+\" * \"+str(b)\n",
    "            res.append(instructions)\n",
    "        if str(operation) in \"2\":\n",
    "            digits_1=random.randint(2,4)\n",
    "            digits_2=random.randint(2,digits_1)\n",
    "            a=random.randint(10**(digits_1-1),(10**digits_1)-1)\n",
    "            b=random.randint(max(10**(digits_2-1),1),min((10**digits_2)-1,a))\n",
    "            instructions=str(a)+\" / \"+str(b)\n",
    "            res.append(instructions)\n",
    "        if operation==3:\n",
    "            digits_1=random.randint(2,4)\n",
    "            digits_2=random.randint(2,4)\n",
    "            a=random.randint(10**(digits_1-1),(10**digits_1)-1)\n",
    "            b=random.randint(10**(digits_1-1),(10**digits_1)-1)\n",
    "            instructions=str(a)+\" + \"+str(b)\n",
    "            res.append(instructions)\n",
    "        if operation==4:\n",
    "            digits_1=random.randint(2,4)\n",
    "            digits_2=random.randint(2,digits_1)\n",
    "            a=random.randint(10**(digits_1-1),(10**digits_1)-1)\n",
    "            b=random.randint(max(10**(digits_2-1),1),min((10**digits_2)-1,a))\n",
    "            instructions=str(a)+\" - \"+str(b)\n",
    "            res.append(instructions)\n",
    "    return res\n",
    "eval_set=get_eval_set(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def to_ans(s):\n",
    "    number_1=\"\"\n",
    "    i=0\n",
    "    while s[i]!=\" \":\n",
    "        number_1+=s[i]\n",
    "        i+=1\n",
    "    symbol=s[i+1]\n",
    "    is_div=False\n",
    "    if s[i+1]==\"/\":\n",
    "        is_div=True\n",
    "    i+=3\n",
    "    number_2=\"\"\n",
    "    while i<len(s):\n",
    "        number_2+=s[i]\n",
    "        i+=1\n",
    "    res=space(str(math.floor(eval(s))))\n",
    "    if is_div:\n",
    "        res+=\" remainder \"+space(str(int(number_1)%int(number_2)))\n",
    "    return res\n",
    "def eval_model(model_path,eval_set):\n",
    "    model,tokenizer=load_model_tokenizer_for_generate(os.path.join(\"/home/mcwave/models/pythia_models/arithmetic\",model_path))\n",
    "    correct=0\n",
    "    incorrect=0\n",
    "    num_checked=0\n",
    "    sym2idx={\"+\":0,\"-\":1,\"*\":2,\"/\":3}\n",
    "    for instruction in eval_set[200:]:\n",
    "        response = generate_response(instruction, model=model, tokenizer=tokenizer)\n",
    "        it=len(response)-1\n",
    "        while response[it]!=\"=\":\n",
    "            it-=1\n",
    "        response_num=response[it+2:len(response)]\n",
    "        if response_num==to_ans(instruction):\n",
    "            correct+=1\n",
    "        else:\n",
    "            incorrect+=1\n",
    "            symbol=\"\"\n",
    "            i=0\n",
    "            while instruction[i] not in \"+-*/\":\n",
    "                i+=1\n",
    "            symbol=instruction[i]\n",
    "            i=0\n",
    "            number=\"\"\n",
    "            while instruction[i]!=\" \":\n",
    "                number+=instruction[i]\n",
    "                i+=1\n",
    "        if num_checked%5==4:\n",
    "            print(\"Correct:\",correct)\n",
    "            print(\"Incorrect:\",incorrect)\n",
    "        num_checked+=1\n",
    "    print(\"Model Path:\",model_path)\n",
    "for path in paths[2:]:\n",
    "    eval_model(path,eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The product of 45 and 5012 is 225,540.\n",
      "The quotient of 96 divided by 79 is approximately 1.2152.\n",
      "1520 multiplied by 130 equals 197,600.\n",
      "74 multiplied by 87 equals 6438.\n",
      "The product of 9928 and 63 is 625,464.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "f=open(\"/home/mcwave/data/word_problems_test/word_problems_test.json\")\n",
    "data=json.load(f)\n",
    "\n",
    "import openai\n",
    "\n",
    "def to_prompt(question):\n",
    "    return \"For the question \"+question+\" , multiply all numbers in the question by 2, then tell me the modified question and the final number in its answer. Do not say anything else.\"\n",
    "\n",
    "class ChatBot:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "    \n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "    \n",
    "    def execute(self):\n",
    "        completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=self.messages)\n",
    "        # Uncomment this to print out token usage each time, e.g.\n",
    "        # {\"completion_tokens\": 86, \"prompt_tokens\": 26, \"total_tokens\": 112}\n",
    "        # print(completion.usage)\n",
    "        return completion.choices[0].message.content\n",
    "    \n",
    "openai.api_key=\"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\"\n",
    "verifier=ChatBot()\n",
    "for i in range(500):\n",
    "    verifier(eval_set[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Modified question: Natalia sold clips to 480 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\\n\\nFinal answer: 5040.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=to_prompt('Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?')\n",
    "verifier(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
       " 'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"problems\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f=open(\"/home/mcwave/data/word_problems/word_problems_train_data_2/word_problems_train_data.jsonl\")\n",
    "data=json.load(f)\n",
    "with open(\"/home/mcwave/data/word_problems/word_problems_train_data_2/word_problems_train_data_2.jsonl\", \"a\") as outfile:\n",
    "    outfile.write(\"\\n\")\n",
    "for question in data:\n",
    "    with open(\"/home/mcwave/data/word_problems/word_problems_train_data_2/word_problems_train_data_2.jsonl\", \"a\") as outfile:\n",
    "        new_q={\"instruction\":question[\"question\"], \"context\": \"\", \"category\": \"open_qa\", \"response\": question[\"answer\"]}\n",
    "        json.dump(new_q,outfile)\n",
    "        outfile.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
